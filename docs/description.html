<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>What the course is about</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Multimodal Interaction</strong> <span>Ginzburg &amp; Lücking</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="description.html">What the course is about</a></li>
							<li><a href="lecture1.html">Lecture 1</a></li>
							<li><a href="lecture2.html">Lecture 2</a></li>
							<li><a href="lecture3.html">Lecture 3</a></li>
							<li><a href="lecture4.html">Lecture 4</a></li>
							<li><a href="lecture5.html">Lecture 5</a></li>
						</ul>
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>What the course is about</h1>
							</header>
							<div class="content">
								<p>Abstract and overview</p>
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Abstract</h2>
									</header>
									<p>Recent years have seen an increased interest of formal linguistics into so-called non-verbal communication signals, in particular manual co-speech gestures. The ecological niche of gestures (and speech), however, is face-to-face interaction, or multimodal dialogue.  Accordingly, there are many gestures which are related to the previous (inter-speaker) or to simultaneous (intra-speaker) dialogue moves. Hence, for an analysis of multimodal dialogue at least two kinds of formal tools are needed: a dialogue theory and a means to represent gestures in addition to speech. The course provides both: it introduces an existing dialogue framework and shows how to adapt it to multimodal interaction. The resulting multimodal analyses involve phenomena from various provenance such as laughter, iconic gesture, frowns, and head shaking.</p>
								</div>
							</section>
							<section>
								<div class="inner">
									<header class="major">
										<h2>Multimodal Interaction in Dialogue and its Meaning</h2>
									</header>
									<p>In most instances, communication involves more than words. From cradle to final days, humans accompany verbal signals with various non-verbal social signals, including laughs, smiles, sighs, frowns, hand-and-arm movements, and a variety of other gestures. Understanding the import of such non-verbal social signals (NVSS), particularly laughter, has interested philosophers for millennia. More recently, NVSS have become an object of study for researchers including psychologists, biologists, neuroscientists, and linguists. </p>
									
									<p>In the first part of the course we will introduce the notion(s) of multimodality (Lücking &amp; Pfeiffer 2012) <!-- \citep{Luecking:Pfeiffer:2012} --> and basic semiotic gesture taxonomies (Lücking 2021), and present the  KoS framework (Ginzburg 2012), <!-- \citep{ginzburg-nlphandbook,ginzburg-buke,ginzburg-cam},--> which is formally underpinned by a <em>Type Theory with Records</em> (TTR; Cooper &amp; Ginzburg 2015, Cooper forthc.). KoS synthesizes: speech act theory, Wittgensteinian language games, formal semantics, emotion representation from cognitive psychology and AI, and conversational analysis to yield a detailed theory of dialogical relevance from the micro-level (self-repairs, interjections; Ginzburg, Fernández &amp; Schlangen 2014) to the macro-level (the structure of complete conversations; Wong 2018). This provides a theory of context that can underpin the analysis of a variety of dialogical phenomena such as non-sentential utterances, repair, and quotation <!-- \citep{raquel-diss,gfs-sp,purver-thesis,ginzburg-cooper-jolli14} --> (Fernández, 2006; Ginzburg, Fernández, and Schlangen, 2014; Purver, 2004; Ginzburg and Cooper, 2014), which are also part and parcel of multimodal interaction.</p>
								<p>Non-verbal gestures have been observed to contribute on various semantic levels: reference (most notably pointing gestures), property exemplification (most notably iconic gestures), signalling attitudes (e.g. facial expressions), or performing complete speech acts (typically emblematic gestures). In the second part of the course, the background developed in the first part is applied to multimodal phenomena from the various levels. In particular, we cover co-speech iconic gestures (Lücking 2016) and laughter (Ginzburg, Mazzocconi and Tian 2020) in some detail, but also look at sighs (Cash and Ginzburg 2019), frowns and head shakes. With <em>partiturs</em> (Lücking and Ginzburg 2020), we introduce a generalized  format for multimodal integration and discuss several representational end empirical problems that still have to be solved. In particular, we consider how to extend a theory of relevance developed to relate utterances that follow each other temporally (<em>horizontal relevance</em>) to utterances/multimodal signals that occur simultaneously (<em>vertical relevance</em>).</p> 

								<p>Participants acquire a basic background of notions and challenges of multimodal interaction.  They get acquainted with a comprehensive, uniform formal framework for studying speech and gesture in dialogue. Analyses of selected phenomena introduces participants to recent advances in the field. The course is  likewise of interest for students interested in dialogue and formal linguists interested in meaning beyond single sentences. 
								</p>
								</div>
							</section>
							<section>
								<div class="inner">
									<header class="major">
										<h2>References</h2>
									</header>
							<ul class="alt">
							<li>Cash, Christopher and Jonathan Ginzburg (2019). &quot;A Sigh of Positivity: an Annotation scheme for sighs in dialogue&quot;. In: Proceedings of SemDial 2019 (Londonlogue), pp. 35&ndash;43. url: <a href="http://semdial.org/anthology/Z19-Cash_semdial_0007.pdf" target="_blank">http://semdial.org/anthology/Z19-Cash_semdial_0007.pdf</a>.</li>
							
							<li>Cooper, Robin (forthc). <em>From Perception to Communication: a Theory of Types for Action and Meaning</em>. Oxford University Press.</li>
							
							<li>Cooper, Robin and Jonathan Ginzburg (2015). &quot;Type theory with records for natural language semantics&quot;. In S. Lappin and C. Fox, eds., <em>The Handbook of Contemporary Semantic Theory</em>, chap. 12, pages 375–407. Oxford, UK: Wiley-Blackwell, 2nd edn. (<a href="https://hal.archives-ouvertes.fr/hal-01138034" target="_blank">Preprint</a>)</li>
							
							<li>Fernández, Raquel (2006). &quot;Non-Sentential Utterances in Dialogue: Classification, Resolution and Use&quot;. PhD thesis. King's College, London.</li>
							
							<li>Ginzburg, Jonathan and Robin Cooper (2014). &quot;Quotation via Dialogical Interaction&quot;. In: Journal of Logic, Language, and Information 23.3, pp. 287&ndash;311. </li>
							
							<li>Ginzburg, Jonathan, Raquel Fernández, and David Schlangen (2014). &quot;Disfluencies as Intra-Utterance Dialogue Moves&quot;. In: Semantics and Pragmatics 7.9, pp. 1&ndash;64</li>
							
							<li>Ginzburg, Jonathan, Chiara Mazzocconi, and Ye Tian (2020). &quot;Laughter as Language&quot;. <em>Glossa: A Journal of General Linguistics</em>, 5(1), 104, DOI: <a href="https://www.glossa-journal.org/article/id/5352/" target="_blank">10.5334/gjgl.1152</a></li>
							
							<li>Lücking, Andy (2016). &quot;Modeling Co-Verbal Gesture Perception in Type Theory with Records&quot;. In: Proceedings of the 2016 Federated Conference on Computer Science and Information Systems, pp. 383&ndash;392.</li> 
							
							<li>Lücking, Andy (2021). &quot;Gesture&quot;. In: <em>Head Driven Phrase Structure Grammar: The handbook.</em> Ed. by Stefan Müller, Anne Abeillé, Robert D. Borsley and Jean-Pierre Koenig. Empirically Oriented Theoretical Morphology and Syntax 9. Berlin: Language Science Press. Chap. 27, pp. 1201&ndsdh;1250. doi: 10.5281/zenodo.5543318. url: <a href="https://langsci-press.org/catalog/book/259">https://langsci-press.org/catalog/book/259</a></li>
							
							<li>Lücking, Andy and Jonathan Ginzburg (2020). &quot;Towards the score of communication&quot;. In: Proceedings of the 24th Workshop on the Semantics and Pragmatics of Dialogue. SemDial/WatchDial. Brandeis University, Waltham (Watch City), MA</li>

							<li>Lücking, Andy and Thies Pfeiffer (2012). &quot;Framing Multimodal Technical Communication. With Focal Points in Speech-Gesture-Integration and Gaze Recognition&quot;. In: <em>Handbook of Technical Communication</em>. Ed. by Alexander Mehler and Laurent Romary. In collab. with Dafydd Gibbon. Handbooks of Applied Linguistics 8. Berlin and Boston: De Gruyter Mouton. Chap. 18, pp. 591&ndash;644.</li>
							
							<li>Purver, Matthew (2004). &quot;The Theory and Use of Clarification in Dialogue&quot;. PhD thesis. King’s College, London.</li>
							
							<li>Wong, Kwong-Cheong (2018). &quot;Classifying Conversations&quot;. PhD thesis. Université Paris-Diderot (Paris 7).</li>
							</ul>
							</div>
							</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="copyright">
								<li>&copy; Andy Lücking, Jonanthan Ginzburg</li><li>Design: <em>Forty</em> by <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>